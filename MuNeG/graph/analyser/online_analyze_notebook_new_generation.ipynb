{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append('D:\\pycharm_workspace\\multiplex\\MuNeG')\n",
    "import graph.analyser.StatisticalAnalysis as sa\n",
    "from pandas.core.frame import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = sa.connect_to_data(\"localhost\", \"DanioRerio\", \"Adrian\", \"A;dek.89\")\n",
    "cursor.execute('select avg(fusion_sum), avg(fusion_mean), homogenity, real_homogenity from [DanioRerio].[muneg].[results_df] group by homogenity, real_homogenity')\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_sum  = [row[0] for row in results]\n",
    "fusion_mean = [row[1] for row in results]\n",
    "homogenity = [row[2] for row in results]\n",
    "real_homogenity = [row[3] for row in results]\n",
    "\n",
    "\n",
    "res_dict = []\n",
    "res_dict.append((\"fusion_sum\", fusion_sum))\n",
    "res_dict.append((\"fusion_mean\", fusion_mean))\n",
    "res_dict.append((\"homogenity\", homogenity))\n",
    "res_dict.append((\"real_homogenity\", real_homogenity))\n",
    "df =  DataFrame.from_items(res_dict)\n",
    "df_pivoted = df.pivot(\"homogenity\", \"real_homogenity\", \"fusion_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.heatmap(df_pivoted, yticklabels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = sa.connect_to_data(\"localhost\", \"DanioRerio\", \"Adrian\", \"A;dek.89\")\n",
    "cursor.execute('select fusion_sum, fusion_mean, fusion_layer, fusion_random, fusion_conv_max, fusion_conv_min, homogenity, baseline, reduction, real_homogenity from [DanioRerio].[muneg].[results_df]')\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_sum = [row[0] for row in results]\n",
    "fusion_mean = [row[1] for row in results]\n",
    "fusion_layer = [row[2] for row in results]\n",
    "fusion_random = [row[3] for row in results]\n",
    "fusion_conv_max = [row[4] for row in results]\n",
    "fusion_conv_min = [row[5] for row in results]\n",
    "homogenity = [row[6] for row in results]\n",
    "baseline = [row[7] for row in results]\n",
    "reduction = [row[8] for row in results]\n",
    "real_homogenity = [row[9] for row in results]\n",
    "\n",
    "homogenity = [int(elem*10) for elem in homogenity]\n",
    "homogenity = sorted(homogenity)\n",
    "\n",
    "res_dict = []\n",
    "res_dict.append((\"SF\", fusion_sum))\n",
    "res_dict.append((\"MF\", fusion_mean))\n",
    "res_dict.append((\"LF\", fusion_layer))\n",
    "res_dict.append((\"RF\", fusion_random))\n",
    "res_dict.append((\"SCF\", fusion_conv_max))\n",
    "res_dict.append((\"FCF\", fusion_conv_min))\n",
    "res_dict.append((\"homogenity\", homogenity))\n",
    "res_dict.append((\"baseline\", baseline))\n",
    "res_dict.append((\"LR\", reduction))\n",
    "res_dict.append((\"real_homogenity\", real_homogenity))\n",
    "df = DataFrame.from_items(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.crayon_palette(['Almond', 'Aquamarine', 'Beaver', 'Blue', 'Copper',  'Vivid Tangerine', 'Magenta', 'Periwinkle','Salmon', 'Sepia', 'Tropical Rain Forest'])\n",
    "palette = sns.color_palette(\"hls\", 11)\n",
    "rc={'axes.labelsize': 15, 'xtick.labelsize': 15, 'ytick.labelsize': 15}\n",
    "sns.set(rc=rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x40f3a4e0>"
      ]
     },
     "execution_count": 17,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "g = sns.PairGrid(df, y_vars=[\"baseline\", \"real_homogenity\"], x_vars=[\"LR\", \"SF\", \"MF\", \"LF\", \"RF\", \"SCF\", \"FCF\"], hue=\"homogenity\", palette=palette)\n",
    "# g.map_diag(plt.hist)\n",
    "g.map(plt.scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print g._legend_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = plt.legend(bbox_to_anchor=(-5.5, 2.20, -3., -1.102), loc=3,\n",
    "           ncol=11, borderaxespad=0.,\n",
    "            frameon=True, fontsize=\"large\", title=\"Homogenity[%]\")\n",
    "for elem in legend.legendHandles:\n",
    "    elem._sizes = [130]\n",
    "plt.setp(legend.get_title(),fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = sa.connect_to_data(\"156.17.131.228\", \"DanioRerio\", \"apopiel\", \"alamakota123\")\n",
    "cursor.execute('select prob_in, real_homogenity, fusion_sum, fusion_mean, fusion_layer, reduction from [DanioRerio].[muneg].[results_df]')\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_in  = [row[0] for row in results]\n",
    "real_homogenity = [row[1] for row in results]\n",
    "fusion_sum = [row[2] for row in results]\n",
    "fusion_mean = [row[3] for row in results]\n",
    "fusion_layer = [row[4] for row in results]\n",
    "reduction = [row[5] for row in results]\n",
    "\n",
    "res_dict = []\n",
    "res_dict.append((\"prob_in\", prob_in))\n",
    "res_dict.append((\"real_homogenity\", real_homogenity))\n",
    "res_dict.append((\"fusion_sum\", fusion_sum))\n",
    "res_dict.append((\"fusion_mean\", fusion_mean))\n",
    "res_dict.append((\"fusion_layer\", fusion_layer))\n",
    "res_dict.append((\"reduction\", reduction))\n",
    "df = DataFrame.from_items(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col=\"prob_in\", ylim=(0, 1))\n",
    "g.map(plt.scatter, \"real_homogenity\", \"reduction\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        prob_in  real_homogenity  fusion_sum  fusion_mean  fusion_layer\n0             5         1.000000        1.00         1.00          1.00\n1             5         1.000000        1.00         1.00          1.00\n2             5         1.000000        1.00         1.00          1.00\n3             5         1.000000        1.00         1.00          1.00\n4             5         1.000000        1.00         1.00          1.00\n5             5         1.000000        1.00         1.00          1.00\n6             5         1.000000        1.00         1.00          1.00\n7             5         1.000000        1.00         1.00          1.00\n8             5         1.000000        1.00         1.00          1.00\n9             5         1.000000        1.00         1.00          1.00\n10            5         1.000000        1.00         1.00          1.00\n11            5         1.000000        1.00         1.00          1.00\n12            5         1.000000        1.00         1.00          1.00\n13            5         1.000000        1.00         1.00          1.00\n14            5         1.000000        1.00         1.00          1.00\n15            5         1.000000        1.00         1.00          1.00\n16            5         1.000000        1.00         1.00          1.00\n17            5         1.000000        1.00         1.00          1.00\n18            5         1.000000        1.00         1.00          1.00\n19            5         1.000000        1.00         1.00          1.00\n20            5         1.000000        1.00         1.00          1.00\n21            5         1.000000        1.00         1.00          1.00\n22            5         1.000000        1.00         1.00          1.00\n23            5         1.000000        1.00         1.00          1.00\n24            5         1.000000        1.00         1.00          1.00\n25            5         1.000000        1.00         1.00          1.00\n26            5         1.000000        1.00         1.00          1.00\n27            5         1.000000        1.00         1.00          1.00\n28            5         1.000000        1.00         1.00          1.00\n29            5         1.000000        1.00         1.00          1.00\n...         ...              ...         ...          ...           ...\n147810        9         0.503927        0.56         0.58          0.57\n147811        9         0.503927        0.57         0.57          0.57\n147812        9         0.503927        0.56         0.56          0.58\n147813        9         0.503927        0.57         0.57          0.57\n147814        9         0.503927        0.56         0.57          0.56\n147815        9         0.503927        0.56         0.59          0.56\n147816        9         0.497382        0.57         0.57          0.57\n147817        9         0.497382        0.58         0.56          0.57\n147818        9         0.497382        0.56         0.57          0.56\n147819        9         0.497382        0.57         0.58          0.60\n147820        9         0.497382        0.58         0.57          0.58\n147821        9         0.497382        0.59         0.53          0.61\n147822        9         0.501606        0.57         0.56          0.59\n147823        9         0.501606        0.55         0.55          0.56\n147824        9         0.501606        0.56         0.56          0.58\n147825        9         0.501606        0.56         0.56          0.59\n147826        9         0.501606        0.57         0.57          0.60\n147827        9         0.501606        0.57         0.57          0.59\n147828        9         0.505184        0.57         0.57          0.57\n147829        9         0.505184        0.57         0.57          0.57\n147830        9         0.505184        0.57         0.58          0.57\n147831        9         0.505184        0.57         0.58          0.57\n147832        9         0.505184        0.57         0.58          0.57\n147833        9         0.505184        0.57         0.59          0.57\n147834        9         0.497953        0.57         0.57          0.60\n147835        9         0.497953        0.56         0.55          0.57\n147836        9         0.497953        0.56         0.57          0.60\n147837        9         0.497953        0.57         0.55          0.58\n147838        9         0.497953        0.57         0.57          0.56\n147839        9         0.497953        0.57         0.56          0.58\n\n[147840 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = sa.connect_to_data(\"156.17.131.228\", \"DanioRerio\", \"apopiel\", \"alamakota123\")\n",
    "cursor.execute('select reduction, fusion_sum, fusion_mean, fusion_layer, fusion_random, fusion_conv_max, fusion_conv_min from [DanioRerio].[muneg].[results_df]')\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction  = [row[0] for row in results]\n",
    "fusion_sum = [row[1] for row in results]\n",
    "fusion_mean = [row[2] for row in results]\n",
    "fusion_layer = [row[3] for row in results]\n",
    "fusion_random = [row[4] for row in results]\n",
    "fusion_conv_max = [row[5] for row in results]\n",
    "fusion_conv_min = [row[6] for row in results]\n",
    "\n",
    "res_dict = []\n",
    "res_dict.append((\"reduction\", reduction))\n",
    "res_dict.append((\"fusion_sum\", fusion_sum))\n",
    "res_dict.append((\"fusion_mean\", fusion_mean))\n",
    "res_dict.append((\"fusion_layer\", fusion_layer))\n",
    "res_dict.append((\"fusion_random\", fusion_random))\n",
    "res_dict.append((\"fusion_conv_max\", fusion_conv_max))\n",
    "res_dict.append((\"fusion_conv_min\", fusion_conv_min))\n",
    "df = DataFrame.from_items(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x3995e080>"
      ]
     },
     "execution_count": 22,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "g = sns.PairGrid(df)\n",
    "g.map_diag(plt.hist)\n",
    "g.map_offdiag(plt.scatter)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = sa.connect_to_data(\"localhost\", \"DanioRerio\", \"Adrian\", \"A;dek.89\")\n",
    "cursor.execute('(select \\'reduction\\', fold, avg(reduction) from  [DanioRerio].[muneg].[results_df] group by fold ) union all (select \\'fusion_sum\\', fold, avg(fusion_sum) from  [DanioRerio].[muneg].[results_df] group by fold) union all  (select \\'fusion_mean\\', fold, avg(fusion_mean) from  [DanioRerio].[muneg].[results_df] group by fold) union all (select \\'fusion_layer\\', fold, avg(fusion_layer) from  [DanioRerio].[muneg].[results_df] group by fold) union all (select \\'fusion_random\\', fold, avg(fusion_random) from  [DanioRerio].[muneg].[results_df] group by fold) union all  (select \\'fusion_conv_max\\', fold, avg(fusion_conv_max) from  [DanioRerio].[muneg].[results_df] group by fold) union all  (select \\'fusion_conv_min\\', fold, avg(fusion_conv_min) from  [DanioRerio].[muneg].[results_df] group by fold);')\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            methods  fold   average\n0         reduction    50  0.572767\n1         reduction    66  0.573461\n2         reduction    75  0.573810\n3         reduction    80  0.573951\n4         reduction    90  0.574614\n5         reduction    95  0.574242\n6        fusion_sum    50  0.647960\n7        fusion_sum    66  0.653253\n8        fusion_sum    75  0.655986\n9        fusion_sum    80  0.656903\n10       fusion_sum    90  0.657927\n11       fusion_sum    95  0.657635\n12      fusion_mean    50  0.645327\n13      fusion_mean    66  0.650437\n14      fusion_mean    75  0.653152\n15      fusion_mean    80  0.653995\n16      fusion_mean    90  0.654829\n17      fusion_mean    95  0.654610\n18     fusion_layer    50  0.646955\n19     fusion_layer    66  0.651850\n20     fusion_layer    75  0.654256\n21     fusion_layer    80  0.655366\n22     fusion_layer    90  0.656291\n23     fusion_layer    95  0.655996\n24    fusion_random    50  0.637604\n25    fusion_random    66  0.641539\n26    fusion_random    75  0.643880\n27    fusion_random    80  0.644564\n28    fusion_random    90  0.645064\n29    fusion_random    95  0.644625\n30  fusion_conv_max    50  0.637567\n31  fusion_conv_max    66  0.641821\n32  fusion_conv_max    75  0.644053\n33  fusion_conv_max    80  0.644766\n34  fusion_conv_max    90  0.645194\n35  fusion_conv_max    95  0.644797\n36  fusion_conv_min    50  0.637199\n37  fusion_conv_min    66  0.641329\n38  fusion_conv_min    75  0.643286\n39  fusion_conv_min    80  0.644318\n40  fusion_conv_min    90  0.644343\n41  fusion_conv_min    95  0.644078\n"
     ]
    }
   ],
   "source": [
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [row[0] for row in  results]\n",
    "fold  = [row[1] for row in results]\n",
    "average = [row[2] for row in results]\n",
    "\n",
    "percent_known = {2 : 50, 3: 66, 4: 75, 5: 80, 10:90, 20:95}\n",
    "percent_from_folds = [percent_known[f] for f in fold]\n",
    "\n",
    "res_dict = []\n",
    "res_dict.append((\"methods\", methods))\n",
    "res_dict.append((\"fold\", percent_from_folds))\n",
    "res_dict.append((\"average\", average))\n",
    "df = DataFrame.from_items(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x19c0f160>"
      ]
     },
     "execution_count": 27,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "rc={'axes.labelsize': 19, 'xtick.labelsize': 19, 'ytick.labelsize': 19, 'xtick.major.width':1205}\n",
    "sns.set(rc=rc)\n",
    "g = sns.factorplot(legend=True, legend_out=True, x=\"methods\", y=\"average\", col=\"fold\", data=df,col_wrap=3,  kind=\"bar\")\n",
    "g.set_axis_labels(\"\", \"Average F1-Score\")\\\n",
    "    .set_xticklabels([\"LR\", \"SF\", \"MF\", \"LF\", \"RF\", \"SCF\", \"FCF\"], rotation=90)\\\n",
    "    .set_titles(\"Known nodes: {col_name}% \")\\\n",
    "    .set(ylim=(0.56, 0.66))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().subplots_adjust(bottom=0.20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = sa.connect_to_data(\"localhost\", \"DanioRerio\", \"Adrian\", \"A;dek.89\")\n",
    "cursor.execute('(select \\'reduction\\', fold, avg(reduction) from  [DanioRerio].[daniorerio].[results_df] group by fold ) union all (select \\'fusion_sum\\', fold, avg(fusion_sum) from  [DanioRerio].[daniorerio].[results_df] group by fold) union all  (select \\'fusion_mean\\', fold, avg(fusion_mean) from  [DanioRerio].[daniorerio].[results_df] group by fold) union all (select \\'fusion_layer\\', fold, avg(fusion_layer) from  [DanioRerio].[daniorerio].[results_df] group by fold) union all (select \\'fusion_random\\', fold, avg(fusion_random) from  [DanioRerio].[daniorerio].[results_df] group by fold) union all  (select \\'fusion_conv_max\\', fold, avg(fusion_conv_max) from  [DanioRerio].[daniorerio].[results_df] group by fold) union all  (select \\'fusion_conv_min\\', fold, avg(fusion_conv_min) from  [DanioRerio].[daniorerio].[results_df] group by fold);')\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import graph.analyser.nemenyi as nemenyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = sa.connect_to_data(\"localhost\", \"DanioRerio\", \"Adrian\", \"A;dek.89\")\n",
    "cursor.execute('select top (1000) reduction, fusion_sum, fusion_mean, fusion_layer, fusion_random, fusion_conv_max, fusion_conv_min from DanioRerio.muneg.results_df')\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = [row[0] for row in  results]\n",
    "fusion_sum  = [row[1] for row in results]\n",
    "fusion_mean = [row[2] for row in results]\n",
    "fusion_layer = [row[3] for row in results]\n",
    "fusion_random = [row[4] for row in results]\n",
    "fusion_conv_max = [row[5] for row in results]\n",
    "fusion_conv_min = [row[6] for row in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FriedmanchisquareResult(statistic=2679.0842315369237, pvalue=0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(463.28345363784109,\n 6.7862447427056241e-97,\n array([ 0.9  ,  0.001,  0.9  ,  0.001,  0.001,  0.001]),\n array([False,  True, False,  True,  True,  True], dtype=bool))"
      ]
     },
     "execution_count": 19,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "groups = [reduction, fusion_sum, fusion_mean, fusion_layer, fusion_random, fusion_conv_max, fusion_conv_min ]\n",
    "friedman_res = stats.friedmanchisquare(reduction, fusion_sum, fusion_mean, fusion_layer, fusion_random, fusion_conv_max, fusion_conv_min)\n",
    "\n",
    "print friedman_res\n",
    "nemenyi.kw_nemenyi(groups,\n",
    "                   method=\"tukey\",\n",
    "                   to_compare=[(0,1), (0,2), (0,3), (0,4), (0,5), (0,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = sa.connect_to_data(\"localhost\", \"DanioRerio\", \"Adrian\", \"A;dek.89\")\n",
    "cursor.execute('select TOP (1000) reduction, fusion_sum, fusion_mean, fusion_layer, fusion_random, fusion_conv_max, fusion_conv_min from DanioRerio.DANIORERIO.results_df')\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}